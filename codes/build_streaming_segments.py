import os
import io
import re
import json
import pandas as pd
import soundfile as sf
import tgt

############################################################
# 1. configuration
############################################################

PARQUET_PATH = "/data/hf_cache/yodas-granary/data/en000/asr_only/00000000.parquet"
MFA_CORPUS_DIR = "/data/user_data/haolingp/outputs/mfa_corpus_test"
MFA_OUTPUT_DIR = "/data/user_data/haolingp/outputs/mfa_output"
LLM_JSON_PATH = "/data/user_data/haolingp/outputs/llm_segmentation_json/utt_000000.json"

os.makedirs(MFA_CORPUS_DIR, exist_ok=True)

MISALIGNMENT_LOG = "/data/user_data/haolingp/outputs/misalignment_log.json"



############################################################
# 2. From parquet, read N  audio/text â†’ write into corpus
############################################################

def export_corpus(parquet_path, corpus_dir, num_samples=10):
    df = pd.read_parquet(parquet_path)
    df = df.iloc[:num_samples]

    for i, row in df.iterrows():
        audio_bytes = row["audio"]["bytes"]  # äºŒè¿›åˆ¶æ•°æ®ï¼ˆwavï¼‰
        text = row["text"]
        uttid = f"utt_{i}"

        wav_path = os.path.join(corpus_dir, f"{uttid}.wav")
        lab_path = os.path.join(corpus_dir, f"{uttid}.lab")

        # create wav file from bytes
        audio_file = io.BytesIO(audio_bytes) # åŸå§‹éŸ³é¢‘å­—èŠ‚åŒ…è£…æˆä¸€ä¸ªâ€œæ–‡ä»¶å¯¹è±¡â€
        audio, sr = sf.read(audio_file)  #numpy arrayï¼Œ sample rate
        sf.write(wav_path, audio, sr) # ä¿å­˜æˆçœŸæ­£çš„ .wav æ–‡ä»¶

        with open(lab_path, "w") as f:
            f.write(text)

        # print(f"Wrote {wav_path} and {lab_path}")

    print("Done exporting corpus â†’", corpus_dir)
    return df


############################################################
# 3. Analyze and fetch each TextGrid â†’ get word-level timeframe
############################################################

def load_word_alignment(textgrid_path):
    try:
        tg = tgt.read_textgrid(textgrid_path) 
        words = tg.get_tier_by_name("words").intervals # ä» "words" tier å–å¾—æ‰€æœ‰ word intervals

        out = []
        for w in words:
            # è·³è¿‡ç©ºç™½ label
            if w.text.strip():
                out.append({
                    # "word": w.text.lower(), # å•è¯ (ç»Ÿä¸€è½¬æˆå°å†™ä¾¿äºåŒ¹é…)
                    "word": w.text,
                    "start": w.start_time,
                    "end": w.end_time
                })
        
        return out
    
    except Exception as e:
        print(f"âŒ Error loading TextGrid {textgrid_path}: {e}")
        return None


############################################################
# 4. æ„é€  1 ç§’ segments
############################################################

def build_1s_segments(words):
    max_time = words[-1]["end"]
    segments = []


    i = 0          # å½“å‰æ‰«æåˆ°ç¬¬å‡ ä¸ª word
    n = len(words)

    for sec in range(max_time):
        sec_start = sec
        sec_end   = sec + 1
        seg_words = []

        # å°†æŒ‡é’ˆæ¨è¿›åˆ°ç¬¬ä¸€æ¬¡å¯èƒ½ overlap çš„ word
        while i < n and words[i]["end"] <= sec_start:
            i += 1

        # ä» i å¼€å§‹æ”¶é›†æœ¬ç§’çš„æ‰€æœ‰ overlap å•è¯
        j = i
        while j < n and words[j]["start"] < sec_end:
            # overlap æ¡ä»¶ï¼šstart < sec_end ä¸” end > sec_start
            if words[j]["end"] > sec_start:
                seg_words.append(words[j]["word"])
            j += 1

        segments.append({"second": sec, "words": seg_words})
    return segments


############################################################
# 5. å°† LLM chunks åŒ¹é…åˆ° MFA word-level æ—¶é—´
############################################################

def normalize_text(s):
    s = s.lower()
    s = re.sub(r"[^a-z ]+", " ", s)
    return " ".join(s.split())

def match_llm_chunks_to_mfa(llm_chunks, mfa_words):
    mfa_tokens = [normalize_text(w["word"]) for w in mfa_words]
    matched = []

    for chunk in llm_chunks:
        tokens = normalize_text(chunk).split()
        matched_indices = []

        for t in tokens:
            for i, w in enumerate(mfa_tokens):
                if w == t:
                    matched_indices.append(i)
                    break

        if not matched_indices:
            matched.append({"chunk": chunk, "start": None, "end": None})
            continue

        start = min(mfa_words[i]["start"] for i in matched_indices)
        end   = max(mfa_words[i]["end"] for i in matched_indices)

        matched.append({"chunk": chunk, "start": start, "end": end})

    return matched


############################################################
# 6. æŒ‰ 1 ç§’åŒºé—´ emitï¼ˆä¿å®ˆç­–ç•¥ï¼‰
############################################################

def assign_chunks_by_second(aligned_chunks):
    max_time = max(x["end"] for x in aligned_chunks if x["end"] is not None)
    max_second = int(max_time) + 1

    emitted = []
    timeline = []

    for sec in range(max_second):
        sec_end = sec + 1.0
        to_emit = []

        for i, item in enumerate(aligned_chunks):
            if i in emitted:
                continue
            if item["end"] <= sec_end:
                to_emit.append(item["chunk"])
                emitted.append(i)

        timeline.append({"second": sec, "emit": to_emit})

    return timeline


############################################################
# 7. æ„é€ æœ€ç»ˆ streaming source/target è¾“å‡º
############################################################

def build_final_segments(timeline, segmentation_json):
    eng_chunks = segmentation_json["low_latency"]["English"]
    zh_chunks  = segmentation_json["low_latency"]["Chinese"]

    eng2zh = {e: z for e, z in zip(eng_chunks, zh_chunks)}

    source_segments = []
    target_segments = []

    for entry in timeline:
        eng_list = entry["emit"]

        # è‹±æ–‡åŠ ç©ºæ ¼æ‹¼æ¥
        eng_concat = " ".join(eng_list).strip()

        # ä¸­æ–‡ä¸åŠ ç©ºæ ¼æ‹¼æ¥
        zh_concat = "".join(eng2zh.get(e, "") for e in eng_list).strip()

        source_segments.append(eng_concat)
        target_segments.append(zh_concat)

    return {"source": source_segments, "target": target_segments}


############################################################
# 8. main
############################################################

def main():
    print("\n=== Step 1: Export corpus ===")
    export_corpus(PARQUET_PATH, MFA_CORPUS_DIR, num_samples=10)

    print("\n=== Step 2: Load MFA alignment ===")
    tg_path = os.path.join(MFA_OUTPUT_DIR, "utt_0.TextGrid")
    words = load_word_alignment(tg_path)
    print("Loaded words:", words[:10])

    print("\n=== Step 3: LLM segmentation JSON ===")
    with open(LLM_JSON_PATH, "r", encoding="utf-8") as f:
        segmentation_json = json.load(f)

    llm_chunks = segmentation_json["low_latency"]["English"]

    print("\n=== Step 4: Match LLM chunks â†’ MFA timestamps ===")
    aligned_chunks = match_llm_chunks_to_mfa(llm_chunks, words)
    for a in aligned_chunks:
        print(a)

    print("\n=== Step 5: Build timeline ===")
    timeline = assign_chunks_by_second(aligned_chunks)
    print(timeline)

    print("\n=== Step 6: Build final source/target ===")
    final_output = build_final_segments(timeline, segmentation_json)
    print("\nFinal streaming output:\n", final_output)

    print("\nğŸ‰ DONE.")


if __name__ == "__main__":
    main()
